{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Input, concatenate, GlobalAveragePooling2D, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "y = df['label'].to_numpy()\n",
    "X = df.drop('label', axis = 1)\n",
    "X = X.to_numpy().reshape(df.shape[0],28,28,1)\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "X_test = df_test.drop('id', axis=1).to_numpy().reshape(df_test.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.25,\n",
    "                                   height_shift_range=0.25,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.25,\n",
    "                                   horizontal_flip=False)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = 15\n",
    "models = [0] * nets\n",
    "\n",
    "for i in range(nets):\n",
    "    models[i] = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=5, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=5, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(256, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    models[i].compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "\n",
    "\n",
    "history = [0] * nets\n",
    "\n",
    "for j in range(nets):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1)\n",
    "    history[j] = models[j].fit_generator(train_datagen.flow(X_train, y_train, batch_size=64),\n",
    "                              steps_per_epoch=X_train.shape[0] // 64,\n",
    "                              epochs=45,\n",
    "                              validation_data=valid_datagen.flow(X_val, y_val),\n",
    "                              callbacks=[lrs],\n",
    "                              verbose=1)\n",
    "    \n",
    "    print(\"CNN \", j + 1, 'Epochs=45 Train Accuracy=', max(history[j].history['acc']), 'Validation Accuracy=', max(history[j].history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros((X_test.shape[0],10)) \n",
    "for j in range(nets):\n",
    "    results = results + model[j].predict(X_test * 1.0 / 255.0)\n",
    "y_pred = np.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.DataFrame(y_pred, columns=['label'])\n",
    "answer.index.name = 'id'\n",
    "answer.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
